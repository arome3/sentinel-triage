# Sentinel-Triage Environment Configuration
# ═══════════════════════════════════════════════════════════════════════════════
#
# Copy this file to .env and fill in your actual values:
#   cp .env.example .env
#
# IMPORTANT: Never commit .env to version control!
# ═══════════════════════════════════════════════════════════════════════════════


# ═══════════════════════════════════════════════════════════════════════════════
# API PROVIDER KEYS
# ═══════════════════════════════════════════════════════════════════════════════

# OpenAI - Required for embeddings (text-embedding-3-small)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-key-here

# Groq - Required for fast inference (Llama 3.3, Llama Guard)
# Get your key at: https://console.groq.com/keys
GROQ_API_KEY=gsk_your-key-here

# DeepSeek - Optional for Tier 2 reasoning (falls back to OpenAI if not set)
# Get your key at: https://platform.deepseek.com
DEEPSEEK_API_KEY=


# ═══════════════════════════════════════════════════════════════════════════════
# ROUTER CONFIGURATION
# ═══════════════════════════════════════════════════════════════════════════════

# Minimum similarity score to match a route (0.0 - 1.0)
# Lower values = more matches, higher values = stricter matching
# Default: 0.7
SIMILARITY_THRESHOLD=0.7

# Route to use when no route matches above the similarity threshold
# Valid options: obvious_harm, obvious_safe, ambiguous_risk, system_attack, non_english
# Default: obvious_safe
DEFAULT_ROUTE=obvious_safe

# Model to use when routing fails entirely
# Default: llama-3.1-8b
FALLBACK_MODEL=llama-3.1-8b


# ═══════════════════════════════════════════════════════════════════════════════
# EMBEDDING CONFIGURATION
# ═══════════════════════════════════════════════════════════════════════════════

# OpenAI embedding model for semantic routing
# Recommended: text-embedding-3-small (fast, cheap, good quality)
# Alternative: text-embedding-3-large (higher quality, slower)
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# Embedding vector dimensions
# Must match the model's output dimensions
# text-embedding-3-small: 1536, text-embedding-3-large: 3072
EMBEDDING_DIMENSIONS=384


# ═══════════════════════════════════════════════════════════════════════════════
# COST TRACKING
# ═══════════════════════════════════════════════════════════════════════════════

# Enable cost calculation and logging for the /metrics endpoint
# Set to false to disable cost tracking
TRACK_COSTS=true

# GPT-4o cost per 1M tokens (used as baseline for "hypothetical" cost)
# This is used to calculate cost savings vs. monolithic approach
GPT4O_COST_PER_1M=5.00


# ═══════════════════════════════════════════════════════════════════════════════
# LOGGING
# ═══════════════════════════════════════════════════════════════════════════════

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# DEBUG: Verbose logging for development
# INFO: Normal operation logging
# WARNING: Only warnings and errors
LOG_LEVEL=INFO


# ═══════════════════════════════════════════════════════════════════════════════
# SERVER
# ═══════════════════════════════════════════════════════════════════════════════

# Host to bind the server to
# Use 0.0.0.0 for all interfaces, 127.0.0.1 for localhost only
HOST=0.0.0.0

# Port to run the server on
PORT=8000

# Enable debug mode (enables auto-reload, detailed errors)
# Set to true for development, false for production
DEBUG=false
